---
title: "STAT 331 Portfolio"
author: "Carson Freedman"
format: 
  html: 
    self-contained: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be a B.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from a Lab or Challenge assignment where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv`

```{r wd-1-csv}
# Lab 2, q1
surveys <- read_csv(file = here("Week2", "Lab2", "surveys.csv"))
```

-   `xlsx`

```{r wd-1-xlsx}
# Preview 2.2, q4
# Code to read in the ages.xlsx data goes here! 
ages_xlsx = readxl::read_xlsx(here::here("Week2", "Preview", "Ages_Data", "ages.xlsx"))
```

-   `txt`

```{r wd-1-txt}
# Preview 2.2, q2
# Code to read in the ages_mystery.txt data goes here! 
ages_mystery <- read_delim(here::here("Week2", "Preview", "Ages_Data", 
                                      "ages_mystery.txt"), delim = "|")
```

**WD-2: I can select necessary columns from a dataset.**

```{r wd-2}
# Lab 3, q8
hiphop_clean |>
  select(subj, sex, age, ethnic) |>
  distinct(.keep_all = TRUE) |>
  subset(sex != "Female") |>
  subset(ethnic == "white") |>
  summary()
```

**WD-3: I can filter rows from a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

```{r wd-3-numeric}
# Lab 3, q11
hiphop_clean |>
  mutate(familiarity = as.numeric(familiarity)) |>
  filter(age < 20) |>
  group_by(word) |>
  summarise(avg = mean(familiarity)) |>
  arrange(desc(avg))
```

-   character -- specifically a string

```{r wd-3-string}
# Lab 3, q12
hiphop_clean |>
  mutate(familiarity = as.numeric(familiarity)) |>
  filter(sex == "Female" & ethnic == "non-white") |>
  group_by(word) |>
  summarise(avg = mean(familiarity)) |>
  arrange(desc(avg))
```

-   factor

```{r wd-3-factor}

```

-   date

```{r wd-3-date}
# Practice 5, q3
thanksgiving <- mdy("November 22nd, 2018", tz = "America/Los_Angeles") 
tg_interval <- (thanksgiving - days(35)) %--% (thanksgiving + days(35))

suspects <- suspects |>
  filter(Time.Spotted %within% tg_interval)
```

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

```{r wd-4-numeric}
# Lab 3, q12
hiphop_clean |>
  mutate(familiarity = as.numeric(familiarity)) |>
  filter(sex == "Female" & ethnic == "non-white") |>
  group_by(word) |>
  summarise(avg = mean(familiarity)) |>
  arrange(desc(avg))
```

-   character -- specifically a string

```{r wd-4-string}
# Lab 3, q7
hiphop_clean <- hiphop_clean |>
  mutate(ethnic = if_else(condition = ethnic == "white", true = "white", 
                          false = "non-white"))
```

-   factor

```{r wd-4-factor}
# Lab 5, part 2 q3
halfweek_captures <- surveys |>
  count(day_of_week) |>
  drop_na() |>
  mutate(
    day_of_week = fct_collapse(day_of_week, 
                               "Weekday" = c("Mon", "Tue", "Wed", "Thu", "Fri"),
                               "Weekend" = c("Sat", "Sun")
    )
  )
```

-   date

```{r wd-4-date}
# Practice 5, q6
epoch <- mdy("January 1st, 1970")
suspects |>
  mutate(diff = difftime(time1 = Time.Spotted, time2 = epoch, units = "mins"))
```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()`

```{r wd-5-left}

```

-   `right_join()`

```{r wd-5-right}

```

-   `inner_join()`

```{r wd-5-inner}
# Preview 4.3, q1
inner_join(prof_info, prof_course)
```

-   `full_join()`

```{r wd-5-full}
# Preview 4.3, q2
full_join(prof_info, prof_course)
```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`

```{r wd-6-semi}
# Lab 4, q6
cali_remove <- tibble(region = c("LosAngeles", "SanDiego", "Sacramento", 
                                  "SanFrancisco"))

diffs <- avocados |>
  semi_join(cali_remove) |>
  group_by(region, type, year) |>
  summarize(mean(AveragePrice))
```

-   `anti_join()`

```{r wd-6-anti}
# Lab 4, q2
regions <- tibble(region = c("West", "GreatLakes", "Midsouth", "Plains", 
                             "SouthCentral", "Southeast", "TotalUS", 
                             "NorthernNewEngland", "Northeast"))

avocados |>
  anti_join(regions) |> # remove regions with filtering join
  rename(location = region)
```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`

```{r wd-7-long}
# Practice 4, q4
pivoted <- military_clean |>
  pivot_longer(names_to = "Year", values_to = "Spending", -c(`Country`, `Notes`, `Reporting year`))
```

-   `pivot_wider()`

```{r wd-7-wide}
# Lab 4, q6
diffs |>
  group_by(region, type) |>
  summarize(price = mean(`mean(AveragePrice)`)) |>
  pivot_wider(names_from = type, values_from = price)
```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

I've done this in the following provided assignments: Lab 2, Challenge 2, Lab 3, Challenge 3, Lab 5 (Revised)

**R-2: I can write well documented and tidy code.**

-   Example 1
    -   Named code chunks

```{r r-2-1}
# Lab 2, q6
#```{r jitter}
ggplot(data = surveys, mapping = aes(x = weight, y = hindfoot_length)) +
  geom_jitter(alpha = 0.1, width = 0.2, height = 0.2) +
  labs(x = "Weight of Rodent (g)", y = "Rodent Hindfoot Length (mm)")
#```
```

-   Example 2
    -   Commented pipeline steps

```{r r-2-2}
# Lab 3, q5
hiphop_clean <- hiphop |> 
  # replace all NA values with zeroes
  mutate(across(.cols = numPreferredArtists:numOverallArtists, 
                .fns = ~replace_na(., replace = 0)),
         # replace zeroes in city & county cols with NA
         across(.cols = city:county, .fns = ~na_if(x = ., y = 0)),
         # convert likert scores stored as nums to factors
         across(.cols = c("familiarity", "jayz", "barkley", "boondocks", 
                          "monique", "bieber"), .fns = factor))
```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example 1

```{r r-3-1}
# Challenge 3, q1
music |>
  select("sex", "intl", "vocal", "classical", "folk", "rock", 
         "country", "pop", "alternative", "hiphop", "unclassifiable") |>
  distinct(.keep_all = TRUE) |>
  group_by(sex) |>
  summarize(across(.cols = is.numeric, .fns = mean))
```

-   Example 2

```{r r-3-2}
# Lab 3, q8
hiphop_clean |>
  select(subj, sex, age, ethnic) |>
  distinct(.keep_all = TRUE) |>
  subset(sex == "Male") |>
  subset(ethnic == "non-white") |>
  count() |>
  summary()
```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   numeric variables

```{r dvs-1-num}
# Lab 2, q5
ggplot(data = surveys, mapping = aes(x = weight, y = hindfoot_length)) +
  geom_point(alpha = 0.1) +
  labs(x = "Weight of Rodent (g)", y = "Rodent Hindfoot Length (mm)")
```

-   numeric variables and categorical variables

```{r dvs-2-num-cat}
# Challenge 2, q1 & q2
ggplot(data = surveys, mapping = aes(x = weight, y = species)) +
  geom_density_ridges(mapping = aes(color = genus, fill = genus)) +
  geom_jitter(size = 0.5, width = 0.1, height = 0.05, alpha = 0.15, 
              color = "darkseagreen") +
  scale_color_viridis_d(option = "D", aesthetics = c("color", "fill")) +
  labs(title = "Weights of Various Rodent Species", x = "Rodent Weight (g)", 
       y = "Species of Rodent", color = "Rodent Genus", fill = "Rodent Genus")
```

-   categorical variables

```{r dvs-2-cat}
# Lab 3, q10
ggplot(data = hiphop_clean, mapping = aes(x = age, fill = ethnic)) +
  geom_bar() +
  labs(x = "Age of Participant", y = "Number of Responses", fill = "Ethnicity")
```

-   dates

```{r dvs-2-date}
# Lab 5, q2 (revised)
mean_weights <- surveys |>
  group_by(genus, date) |>
  summarize(weight = mean(weight))

ggplot(data = mean_weights, mapping = aes(x = date, y = weight, 
                                          color = genus)) +
  geom_line() +
  theme_minimal() +
  labs(x = "Year", y = "", title = "Weight of Rodent by Species (g)")
```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   Example 1

```{r dvs-2-1}
# Challenge 2, q1 & q2
ggplot(data = surveys, mapping = aes(x = weight, y = species)) +
  geom_density_ridges(mapping = aes(color = genus, fill = genus)) +
  geom_jitter(size = 0.5, width = 0.1, height = 0.05, alpha = 0.15, 
              color = "darkseagreen") +
  scale_color_viridis_d(option = "D", aesthetics = c("color", "fill")) +
  labs(title = "Weights of Various Rodent Species", x = "Rodent Weight (g)", 
       y = "Species of Rodent", color = "Rodent Genus", fill = "Rodent Genus")
```

-   Example 2

```{r dvs-2-2}
# Lab 5, q2 (revised)
ggplot(data = surveys, mapping = aes(x = weight, 
                                     y = fct_reorder(species, weight))) +
  geom_jitter(width = 0.1, height = 0.1, color = "tomato", alpha = 0.2) +
  geom_boxplot(outlier.alpha = 0) +
  labs(x = "Weight", y = "", title = "Weight of Rodent by Genus (g)")
```

**DVS-3: I show creativity in my visualizations**

-   Example 1

```{r dvs-3-1}
# Challenge 2, q1 & q2
ggplot(data = surveys, mapping = aes(x = weight, y = species)) +
  geom_density_ridges(mapping = aes(color = genus, fill = genus)) +
  geom_jitter(size = 0.5, width = 0.1, height = 0.05, alpha = 0.15, 
              color = "darkseagreen") +
  scale_color_viridis_d(option = "D", aesthetics = c("color", "fill")) +
  labs(title = "Weights of Various Rodent Species", x = "Rodent Weight (g)", 
       y = "Species of Rodent", color = "Rodent Genus", fill = "Rodent Genus")
```

-   Example 2

```{r dvs-3-2}
# Lab 3, q10
ggplot(data = hiphop_clean, mapping = aes(x = age, fill = sex)) +
  geom_bar() +
  labs(x = "Age of Participant", y = "Number of Responses", fill = "Sex")
```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example 1

```{r dvs-4-1}
# Lab 3, q12
hiphop_clean |>
  mutate(familiarity = as.numeric(familiarity)) |>
  filter(sex == "Female" & ethnic == "non-white") |>
  group_by(word) |>
  summarise(avg = mean(familiarity)) |>
  arrange(desc(avg))
```

-   Example 2

```{r dvs-4-2}
# Lab 4, q4
regional_avocados |>
  separate(col = Date, sep = "-", into = c("year", "month", "day")) |>
  group_by(month) |>
  summarise(sum(`Total Volume`)) |>
  arrange(desc(`sum(\`Total Volume\`)`)) |>
  slice_head()
```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1

```{r dvs-5-1}
# Lab 4, q6
cali_remove <- tibble(region = c("LosAngeles", "SanDiego", "Sacramento", 
                                  "SanFrancisco"))
diffs <- avocados |>
  semi_join(cali_remove) |>
  group_by(region, type, year) |>
  summarize(mean(AveragePrice))
```

-   Example 2

```{r dvs-5-2}
# Lab 4, q6
diffs |>
  group_by(region, type) |>
  summarize(price = mean(`mean(AveragePrice)`)) |>
  pivot_wider(names_from = type, values_from = price)
```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   Example 1

```{r dvs-6-1}
# Challenge 3, q1
music |>
  select("sex", "intl", "vocal", "classical", "folk", "rock", 
         "country", "pop", "alternative", "hiphop", "unclassifiable") |>
  distinct(.keep_all = TRUE) |>
  group_by(sex) |>
  summarize(across(.cols = is.numeric, .fns = mean))
```

-   Example 2

```{r dvs-6-2}
# Lab 3, q12
hiphop_clean |>
  mutate(familiarity = as.numeric(familiarity)) |>
  filter(sex == "Female" & ethnic == "non-white") |>
  group_by(word) |>
  summarise(avg = mean(familiarity)) |>
  arrange(desc(avg))
```

**DVS-7: I show creativity in my tables.**

-   Example 1

```{r dvs-7-1}
# Challenge 3, q2
music |>
  select("ethnic", "intl", "vocal", "classical", "folk", "rock", 
         "country", "pop", "alternative", "hiphop", "unclassifiable") |>
  mutate(ethnic = if_else(condition = ethnic == "white", true = "white", 
                          false = "non-white")) |>
  distinct(.keep_all = TRUE) |>
  group_by(ethnic) |>
  summarize(across(.cols = is.numeric, .fns = mean))
```

-   Example 2

```{r dvs-7-2}
# Lab 3, q12
hiphop_clean |>
  mutate(familiarity = as.numeric(familiarity)) |>
  filter(sex == "Female" & ethnic == "non-white") |>
  group_by(word) |>
  summarise(avg = mean(familiarity)) |>
  arrange(desc(avg))
```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call

```{r pe-1-one-call}
# Lab 3, q7
hiphop_clean <- hiphop_clean |>
  mutate(ethnic = if_else(condition = ethnic == "white", true = "white", 
                          false = "non-white"))
```

-   `across()`

```{r pe-1-across}
# Lab 3, q5
hiphop_clean <- hiphop |> 
  # replace all NA values with zeroes
  mutate(across(.cols = numPreferredArtists:numOverallArtists, 
                .fns = ~replace_na(., replace = 0)),
         # replace zeroes in city & county cols with NA
         across(.cols = city:county, .fns = ~na_if(x = ., y = 0)),
         # convert likert scores stored as nums to factors
         across(.cols = c("familiarity", "jayz", "barkley", "boondocks", 
                          "monique", "bieber"), .fns = factor))
```

-   `map()` functions

```{r pe-1-map-1}

```

**PE-2: I can write functions to reduce repetition in my code.**

-   Example 1

```{r pe2-1}

```

-   Example 2

```{r pe2-2}

```

**PE-3:I can use iteration to reduce repetition in my code.**

-   `across()`

```{r pe-3-across}
# Challenge 3, q2
music |>
  select("sex", "intl", "vocal", "classical", "folk", "rock", 
         "country", "pop", "alternative", "hiphop", "unclassifiable") |>
  distinct(.keep_all = TRUE) |>
  group_by(sex) |>
  summarize(across(.cols = is.numeric, .fns = mean))
```

-   `map()` functions (Provide 2 Examples)

```{r pe-3-map-1}

```

```{r pe-3-map-2}

```

**PE-4: I can use modern tools when carrying out my analysis.**

-   Example 1
    -   Mutate across

```{r pe-4-1}
# Lab 3, q5
hiphop_clean <- hiphop |> 
  # replace all NA values with zeroes
  mutate(across(.cols = numPreferredArtists:numOverallArtists, 
                .fns = ~replace_na(., replace = 0)),
         # replace zeroes in city & county cols with NA
         across(.cols = city:county, .fns = ~na_if(x = ., y = 0)),
         # convert likert scores stored as nums to factors
         across(.cols = c("familiarity", "jayz", "barkley", "boondocks", 
                          "monique", "bieber"), .fns = factor))
```

-   Example 2
    -   Summarize across

```{r pe-4-2}
# Challenge 3, q2
music |>
  select("sex", "intl", "vocal", "classical", "folk", "rock", 
         "country", "pop", "alternative", "hiphop", "unclassifiable") |>
  distinct(.keep_all = TRUE) |>
  group_by(sex) |>
  summarize(across(.cols = is.numeric, .fns = mean))
```

## Data Simulation & Modeling

**DSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1

```{r dsm-1-1}

```

-   Example 2

```{r dsm-1-2}

```

**DSM-2: I can fit a linear regression and extract necessary summary measures.**

-   Example 1

```{r dsm-2-1}

```

-   Example 2

```{r dsm-2-2}

```

## Revising My Thinking

<!-- How did you revise your thinking throughout the course? How did you revise your thinking on the code examples you have provided in your portfolio? -->

I have revised my thinking throughout the course thus far by completing a few revisions on assignments where I did not receive all S grades, such as Lab 1 and Lab 2, as well as Lab 5 which I revised and have used snippets of revised code as evidence for a few in my portfolio. I have also revised my thinking by reading and incorporating feedback received on assignments and peer reviews, as well as lessons learned in class during lecture or when completing practice activities.

## Extending My Thinking

<!-- How did you extended your thinking throughout the course? How did you extend your thinking on the code examples you have provided in your portfolio? -->

I have extended my thinking by going above and beyond on certain assignments, such as in Challenge 2. In addition, I have also performed external research when completing assignments such as labs and challenges, after which I was able to review and incorporate aspects of my findings into my solutiuon in order to create efficient and clean code.

## Peer Support & Collaboration

<!-- Include an image of feedback you gave that you are proud of (either in a peer review or in Discord) -->

![](2023-02-19.png)
